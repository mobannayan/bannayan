{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f9b5331",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e30635c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Step 1: Create synthetic data for disease occurrence (binary classification)\n",
    "n_samples = 1500\n",
    "n_features = 10\n",
    "\n",
    "X = np.random.rand(n_samples, n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eae70d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a synthetic target y using some arbitrary rule + noise\n",
    "# Let's say disease occurrence depends on some features with a threshold\n",
    "score = X[:, 0] * 0.6 + X[:, 1] * 0.3 - X[:, 2] * 0.5 + np.random.normal(0, 0.1, n_samples)\n",
    "y = (score > 0.3).astype(int)  # disease present (1) or absent (0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aedbfdfe",
   "metadata": {},
   "source": [
    "This code snippet generates a binary target variable (y) representing disease occurrence (1 = present, 0 = absent) based on a linear combination of features in a NumPy array X. Here's a detailed explanation:\n",
    "X[:, 0], X[:, 1], X[:, 2]:\n",
    "\n",
    "    These represent the first three features (columns) of the dataset X.\n",
    "\n",
    "Coefficients (0.6, 0.3, -0.5):\n",
    "\n",
    "    These are weights that simulate how much each feature contributes to disease risk.\n",
    "\n",
    "    Feature 0 contributes positively (+0.6),\n",
    "\n",
    "    Feature 1 also contributes positively (+0.3),\n",
    "\n",
    "    Feature 2 contributes negatively (-0.5), meaning it reduces the risk.\n",
    "\n",
    "np.random.normal(0, 0.1, n_samples):\n",
    "\n",
    "    Adds some random noise to make the data more realistic and less deterministic.\n",
    "\n",
    "    Mean = 0, Standard deviation = 0.1\n",
    "    y = (score > 0.3).astype(int)\n",
    "\n",
    "What this line does:\n",
    "\n",
    "    score > 0.3:\n",
    "\n",
    "        A threshold is applied to classify scores.\n",
    "\n",
    "        If the score is greater than 0.3, disease is assumed to be present (True), otherwise absent (False).\n",
    "\n",
    "    .astype(int):\n",
    "\n",
    "        Converts Boolean values (True, False) to integers (1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5868a6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "859b88be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Set up XGBoost classifier\n",
    "xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8912cf14",
   "metadata": {},
   "source": [
    "These two parameters are used when initializing an XGBClassifier from the XGBoost. xgb = XGBClassifier(use_label_encoder=False)\n",
    "\n",
    "This tells XGBoost:\n",
    "\n",
    "    “Don’t encode my labels — I’ve already got them in the correct format.”     'logloss' stands for logarithmic loss, also known as binary cross-entropy loss.\n",
    "\n",
    "Why it's used:\n",
    "\n",
    "    In binary classification problems, logloss is a commonly used metric that measures how well the model's predicted probabilities match the actual class labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2adf1b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Define hyperparameter grid to tune\n",
    "param_grid = {\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'n_estimators': [50, 100, 150]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1bd6987",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, device=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False,\n",
       "                                     eval_metric='logloss', feature_types=None,\n",
       "                                     gamma=None, grow_policy=None,\n",
       "                                     importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=...\n",
       "                                     max_cat_threshold=None,\n",
       "                                     max_cat_to_onehot=None,\n",
       "                                     max_delta_step=None, max_depth=None,\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     multi_strategy=None, n_estimators=None,\n",
       "                                     n_jobs=None, num_parallel_tree=None,\n",
       "                                     random_state=42, ...),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'learning_rate': [0.01, 0.1, 0.2],\n",
       "                         'max_depth': [3, 5, 7],\n",
       "                         'n_estimators': [50, 100, 150]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 5: Grid search with 5-fold cross-validation\n",
    "grid_search = GridSearchCV(xgb, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9849059a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 50}\n",
      "Best cross-validation accuracy: 0.8883\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Print best parameters and best CV score\n",
    "print(\"Best hyperparameters:\", grid_search.best_params_)\n",
    "print(f\"Best cross-validation accuracy: {grid_search.best_score_:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7d0761f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 0.8667\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.88      0.89       192\n",
      "           1       0.80      0.84      0.82       108\n",
      "\n",
      "    accuracy                           0.87       300\n",
      "   macro avg       0.85      0.86      0.86       300\n",
      "weighted avg       0.87      0.87      0.87       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 7: Evaluate on test set\n",
    "best_xgb = grid_search.best_estimator_\n",
    "y_pred = best_xgb.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test set accuracy: {accuracy:.4f}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
